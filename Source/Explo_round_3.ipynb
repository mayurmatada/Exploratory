{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24f9aa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.optimize import least_squares, basinhopping, differential_evolution, minimize\n",
    "import scipy.constants\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b84ac7",
   "metadata": {},
   "source": [
    "Constants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "525ae639",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 5.405e9\n",
    "c = scipy.constants.c\n",
    "wavelength = c / f\n",
    "k = 2 * np.pi * f / c\n",
    "s = 0.0097\n",
    "sbl = 0.013\n",
    "theta = 40\n",
    "theta = np.deg2rad(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcca6acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"../Data/NorthChinaPlain_SAR_MODIS_LAI_SM_Daily_MAX.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45adac8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "LAI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "SoilMoisture",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "VH",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "VV",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "30e553b5-f61e-4605-9d80-d85670dbcd02",
       "rows": [
        [
         "0",
         "2015-04-01",
         "0.6880226485128322",
         "0.1650650254559665",
         "-16.29296876786129",
         "-7.430980736353476"
        ],
        [
         "1",
         "2015-04-25",
         "1.2719406711701238",
         "0.1732086607088779",
         "-18.557225422549934",
         "-10.515812624489808"
        ],
        [
         "2",
         "2015-05-19",
         "1.2799295143371083",
         "0.1687016074545764",
         "-18.18163992210793",
         "-10.299893535089826"
        ],
        [
         "3",
         "2015-05-21",
         "1.2957639921567847",
         "0.16729857619189206",
         "-31.599209315135397",
         "-25.117548746373384"
        ],
        [
         "4",
         "2015-05-24",
         "1.0967848179682609",
         "0.1643363344335785",
         "-16.61852144854465",
         "-8.8496779316386"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>LAI</th>\n",
       "      <th>SoilMoisture</th>\n",
       "      <th>VH</th>\n",
       "      <th>VV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>0.688023</td>\n",
       "      <td>0.165065</td>\n",
       "      <td>-16.292969</td>\n",
       "      <td>-7.430981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-04-25</td>\n",
       "      <td>1.271941</td>\n",
       "      <td>0.173209</td>\n",
       "      <td>-18.557225</td>\n",
       "      <td>-10.515813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-05-19</td>\n",
       "      <td>1.279930</td>\n",
       "      <td>0.168702</td>\n",
       "      <td>-18.181640</td>\n",
       "      <td>-10.299894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-05-21</td>\n",
       "      <td>1.295764</td>\n",
       "      <td>0.167299</td>\n",
       "      <td>-31.599209</td>\n",
       "      <td>-25.117549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-05-24</td>\n",
       "      <td>1.096785</td>\n",
       "      <td>0.164336</td>\n",
       "      <td>-16.618521</td>\n",
       "      <td>-8.849678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date       LAI  SoilMoisture         VH         VV\n",
       "0  2015-04-01  0.688023      0.165065 -16.292969  -7.430981\n",
       "1  2015-04-25  1.271941      0.173209 -18.557225 -10.515813\n",
       "2  2015-05-19  1.279930      0.168702 -18.181640 -10.299894\n",
       "3  2015-05-21  1.295764      0.167299 -31.599209 -25.117549\n",
       "4  2015-05-24  1.096785      0.164336 -16.618521  -8.849678"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_data(data):\n",
    "    # Drop rows with missing data in column: 'SoilMoisture'\n",
    "    data = data.dropna(subset=['SoilMoisture'])\n",
    "    # Average numeric columns for duplicate dates\n",
    "    data = data.groupby('date', as_index=False).mean(numeric_only=True)\n",
    "    return data\n",
    "\n",
    "\n",
    "data = clean_data(data.copy())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52e77689",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trim_number = 4\n",
    "\n",
    "mean_vv = data['VV'].mean()\n",
    "std_vv = data['VV'].std()\n",
    "\n",
    "data_trimmed = data[(data['VV'] >= mean_vv - trim_number * std_vv) & (data['VV'] <= mean_vv + trim_number * std_vv)]\n",
    "\n",
    "\n",
    "mean_vh = data['VH'].mean()\n",
    "\n",
    "std_vh = data['VH'].std()\n",
    "\n",
    "data_trimmed = data[(data['VH'] >= mean_vh - trim_number * std_vh) & (data['VH'] <= mean_vh + trim_number * std_vv)]\n",
    "\n",
    "VV_dB = data_trimmed['VV'].values\n",
    "VH_dB = data_trimmed['VH'].values\n",
    "SM = data_trimmed['SoilMoisture'].values\n",
    "LAI = data_trimmed['LAI'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3535d644",
   "metadata": {},
   "source": [
    "Trimmed the data at dates which Avoids Rainfall and gets most bare soil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04941c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mayur\\AppData\\Local\\Temp\\ipykernel_2128\\3717637951.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_trimmed['date'] = pd.to_datetime(data_trimmed['date'])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Invalid comparison between dtype=datetime64[ns] and str",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mparsing.pyx:684\u001b[39m, in \u001b[36mpandas._libs.tslibs.parsing.dateutil_parse\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: day is out of range for month",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mDateParseError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Mayur\\Documents\\College\\4th sem\\Exploratory\\.venv\\Lib\\site-packages\\pandas\\core\\arrays\\datetimelike.py:528\u001b[39m, in \u001b[36mDatetimeLikeArrayMixin._validate_comparison_value\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    526\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    527\u001b[39m     \u001b[38;5;66;03m# GH#18435 strings get a pass from tzawareness compat\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m528\u001b[39m     other = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_scalar_from_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, IncompatibleFrequency):\n\u001b[32m    530\u001b[39m     \u001b[38;5;66;03m# failed to parse as Timestamp/Timedelta/Period\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Mayur\\Documents\\College\\4th sem\\Exploratory\\.venv\\Lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:535\u001b[39m, in \u001b[36mDatetimeArray._scalar_from_string\u001b[39m\u001b[34m(self, value)\u001b[39m\n\u001b[32m    534\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_scalar_from_string\u001b[39m(\u001b[38;5;28mself\u001b[39m, value) -> Timestamp | NaTType:\n\u001b[32m--> \u001b[39m\u001b[32m535\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTimestamp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtz\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtz\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mtimestamps.pyx:1865\u001b[39m, in \u001b[36mpandas._libs.tslibs.timestamps.Timestamp.__new__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mconversion.pyx:364\u001b[39m, in \u001b[36mpandas._libs.tslibs.conversion.convert_to_tsobject\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mconversion.pyx:641\u001b[39m, in \u001b[36mpandas._libs.tslibs.conversion.convert_str_to_tsobject\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsing.pyx:336\u001b[39m, in \u001b[36mpandas._libs.tslibs.parsing.parse_datetime_string\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsing.pyx:688\u001b[39m, in \u001b[36mpandas._libs.tslibs.parsing.dateutil_parse\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mDateParseError\u001b[39m: day is out of range for month: 2016-06-31",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mInvalidComparison\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Mayur\\Documents\\College\\4th sem\\Exploratory\\.venv\\Lib\\site-packages\\pandas\\core\\arrays\\datetimelike.py:983\u001b[39m, in \u001b[36mDatetimeLikeArrayMixin._cmp_method\u001b[39m\u001b[34m(self, other, op)\u001b[39m\n\u001b[32m    982\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m983\u001b[39m     other = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_comparison_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidComparison:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Mayur\\Documents\\College\\4th sem\\Exploratory\\.venv\\Lib\\site-packages\\pandas\\core\\arrays\\datetimelike.py:531\u001b[39m, in \u001b[36mDatetimeLikeArrayMixin._validate_comparison_value\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    529\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, IncompatibleFrequency):\n\u001b[32m    530\u001b[39m         \u001b[38;5;66;03m# failed to parse as Timestamp/Timedelta/Period\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m531\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidComparison(other)\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, \u001b[38;5;28mself\u001b[39m._recognized_scalars) \u001b[38;5;129;01mor\u001b[39;00m other \u001b[38;5;129;01mis\u001b[39;00m NaT:\n",
      "\u001b[31mInvalidComparison\u001b[39m: 2016-06-31",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m end_date = \u001b[33m'\u001b[39m\u001b[33m2016-06-31\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Filter the data based on the date range\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m data_segmented = data_trimmed[(data_trimmed[\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m] >= start_date) & (\u001b[43mdata_trimmed\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdate\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m<\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_date\u001b[49m)]\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Extract the relevant columns after filtering\u001b[39;00m\n\u001b[32m     12\u001b[39m VV_dB = data_segmented[\u001b[33m'\u001b[39m\u001b[33mVV\u001b[39m\u001b[33m'\u001b[39m].values\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Mayur\\Documents\\College\\4th sem\\Exploratory\\.venv\\Lib\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[39m, in \u001b[36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     72\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[32m     74\u001b[39m other = item_from_zerodim(other)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Mayur\\Documents\\College\\4th sem\\Exploratory\\.venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:52\u001b[39m, in \u001b[36mOpsMixin.__le__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m__le__\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__le__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mle\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Mayur\\Documents\\College\\4th sem\\Exploratory\\.venv\\Lib\\site-packages\\pandas\\core\\series.py:6119\u001b[39m, in \u001b[36mSeries._cmp_method\u001b[39m\u001b[34m(self, other, op)\u001b[39m\n\u001b[32m   6116\u001b[39m lvalues = \u001b[38;5;28mself\u001b[39m._values\n\u001b[32m   6117\u001b[39m rvalues = extract_array(other, extract_numpy=\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m6119\u001b[39m res_values = \u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6121\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._construct_result(res_values, name=res_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Mayur\\Documents\\College\\4th sem\\Exploratory\\.venv\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:330\u001b[39m, in \u001b[36mcomparison_op\u001b[39m\u001b[34m(left, right, op)\u001b[39m\n\u001b[32m    321\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    322\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mLengths must match to compare\u001b[39m\u001b[33m\"\u001b[39m, lvalues.shape, rvalues.shape\n\u001b[32m    323\u001b[39m         )\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m should_extension_dispatch(lvalues, rvalues) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m    326\u001b[39m     (\u001b[38;5;28misinstance\u001b[39m(rvalues, (Timedelta, BaseOffset, Timestamp)) \u001b[38;5;129;01mor\u001b[39;00m right \u001b[38;5;129;01mis\u001b[39;00m NaT)\n\u001b[32m    327\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m lvalues.dtype != \u001b[38;5;28mobject\u001b[39m\n\u001b[32m    328\u001b[39m ):\n\u001b[32m    329\u001b[39m     \u001b[38;5;66;03m# Call the method on lvalues\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m330\u001b[39m     res_values = \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m is_scalar(rvalues) \u001b[38;5;129;01mand\u001b[39;00m isna(rvalues):  \u001b[38;5;66;03m# TODO: but not pd.NA?\u001b[39;00m\n\u001b[32m    333\u001b[39m     \u001b[38;5;66;03m# numpy does not like comparisons vs None\u001b[39;00m\n\u001b[32m    334\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m op \u001b[38;5;129;01mis\u001b[39;00m operator.ne:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Mayur\\Documents\\College\\4th sem\\Exploratory\\.venv\\Lib\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[39m, in \u001b[36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     72\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[32m     74\u001b[39m other = item_from_zerodim(other)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Mayur\\Documents\\College\\4th sem\\Exploratory\\.venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:52\u001b[39m, in \u001b[36mOpsMixin.__le__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m__le__\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__le__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mle\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Mayur\\Documents\\College\\4th sem\\Exploratory\\.venv\\Lib\\site-packages\\pandas\\core\\arrays\\datetimelike.py:985\u001b[39m, in \u001b[36mDatetimeLikeArrayMixin._cmp_method\u001b[39m\u001b[34m(self, other, op)\u001b[39m\n\u001b[32m    983\u001b[39m     other = \u001b[38;5;28mself\u001b[39m._validate_comparison_value(other)\n\u001b[32m    984\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidComparison:\n\u001b[32m--> \u001b[39m\u001b[32m985\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minvalid_comparison\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    987\u001b[39m dtype = \u001b[38;5;28mgetattr\u001b[39m(other, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    988\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(dtype):\n\u001b[32m    989\u001b[39m     \u001b[38;5;66;03m# We have to use comp_method_OBJECT_ARRAY instead of numpy\u001b[39;00m\n\u001b[32m    990\u001b[39m     \u001b[38;5;66;03m#  comparison otherwise it would raise when comparing to None\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Mayur\\Documents\\College\\4th sem\\Exploratory\\.venv\\Lib\\site-packages\\pandas\\core\\ops\\invalid.py:40\u001b[39m, in \u001b[36minvalid_comparison\u001b[39m\u001b[34m(left, right, op)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     39\u001b[39m     typ = \u001b[38;5;28mtype\u001b[39m(right).\u001b[34m__name__\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid comparison between dtype=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mleft.dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtyp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m res_values\n",
      "\u001b[31mTypeError\u001b[39m: Invalid comparison between dtype=datetime64[ns] and str"
     ]
    }
   ],
   "source": [
    "# Convert the 'Date' column to datetime format\n",
    "data_trimmed['date'] = pd.to_datetime(data_trimmed['date'])\n",
    "\n",
    "# Define the start and end dates for filtering\n",
    "start_date = '2016-04-1'\n",
    "end_date = '2016-06-31'\n",
    "\n",
    "# Filter the data based on the date range\n",
    "data_segmented = data_trimmed[(data_trimmed['date'] >= start_date) & (data_trimmed['date'] <= end_date)]\n",
    "\n",
    "# Extract the relevant columns after filtering\n",
    "VV_dB = data_segmented['VV'].values\n",
    "VH_dB = data_segmented['VH'].values\n",
    "SM = data_segmented['SoilMoisture'].values\n",
    "LAI = data_segmented['LAI'].values\n",
    "\n",
    "# Ensure all arrays have the same length\n",
    "min_length = min(len(VH_dB), len(LAI), len(SM))\n",
    "VH_dB = VH_dB[:min_length]\n",
    "LAI = LAI[:min_length]\n",
    "SM = SM[:min_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a57c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "VV_linear = 10**(VV_dB / 10)\n",
    "VH_linear = 10**(VH_dB / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feeb828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scaler_vv = MinMaxScaler()\\nscaler_vh = MinMaxScaler()\\nscaler_sm = MinMaxScaler()\\nscaler_lai = MinMaxScaler()\\n\\nVV_dB = scaler_vv.fit_transform(VV_dB.reshape(-1, 1)).flatten()\\nVH_dB = scaler_vh.fit_transform(VH_dB.reshape(-1, 1)).flatten()\\nSM = scaler_sm.fit_transform(SM.reshape(-1, 1)).flatten()\\nLAI = scaler_lai.fit_transform(LAI.reshape(-1, 1)).flatten()'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"scaler_vv = MinMaxScaler()\n",
    "scaler_vh = MinMaxScaler()\n",
    "scaler_sm = MinMaxScaler()\n",
    "scaler_lai = MinMaxScaler()\n",
    "\n",
    "VV_dB = scaler_vv.fit_transform(VV_dB.reshape(-1, 1)).flatten()\n",
    "VH_dB = scaler_vh.fit_transform(VH_dB.reshape(-1, 1)).flatten()\n",
    "SM = scaler_sm.fit_transform(SM.reshape(-1, 1)).flatten()\n",
    "LAI = scaler_lai.fit_transform(LAI.reshape(-1, 1)).flatten()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da4864a",
   "metadata": {},
   "source": [
    "L Prevot Original 1993 WCM:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b61e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wcm_1993_sigma_0(P1, P2, P3, P4, P5, L, S):\n",
    "    #P5 > 0 \n",
    "    t2 = np.exp(-2 * P2 * L / np.cos(theta))\n",
    "    sigma_veg = P1 * np.power(L, P5) * np.cos(theta) * (1 - t2) #Including the (1-t2) gets less r2_Score what???\n",
    "    sigma_soil = P3+P4*S\n",
    "    return sigma_veg+(t2*sigma_soil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1c5e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wcm_1993_validate_optimizer(optimizer_func, data):\n",
    "\n",
    "    params_VV = optimizer_func(VV_dB, LAI, SM)\n",
    "    predicted_VV = wcm_1993_sigma_0(*params_VV, LAI, SM)\n",
    "\n",
    "    r2_VV = r2_score(VV_dB, predicted_VV)\n",
    "\n",
    "\n",
    "    params_VH = optimizer_func(VH_dB, LAI, SM)\n",
    "    predicted_VH = wcm_1993_sigma_0(*params_VH, LAI, SM)\n",
    "\n",
    "    r2_VH = r2_score(VH_dB, predicted_VH)\n",
    "\n",
    "    clear_output()\n",
    "    print(f\"R2 Score For VV:{np.median(r2_VV)}\")\n",
    "    print(f\"R2 Score For VH:{np.median(r2_VH)}\")\n",
    "    return (tuple(params_VV), tuple(params_VH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16417c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_wcm_1993_sigma_0_ls(polarization, L, S):\n",
    "    def residuals(params):\n",
    "        predicted = wcm_1993_sigma_0(*params, L, S)\n",
    "        residuals = predicted - polarization\n",
    "        if not np.all(np.isfinite(residuals)):\n",
    "            return np.inf \n",
    "        return residuals\n",
    "    initial_guess = [0.1, 1.3, 1.2, 0.9, 0.8]\n",
    "    result = least_squares(residuals, initial_guess, method='trf', loss='soft_l1', max_nfev=10000)\n",
    "    return result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331db7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score For VV:0.7580455656177528\n",
      "R2 Score For VH:0.3089043193212241\n"
     ]
    }
   ],
   "source": [
    "wcm_1993_params_vv, wcm_1993_params_vh = wcm_1993_validate_optimizer(optimize_wcm_1993_sigma_0_ls, data_segmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2104ee34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score for LAI: -0.27098955658497026\n",
      "R2 Score for SM: -5.91801534652686\n",
      "R2 Score for LAI: 0.4461228300472334\n",
      "R2 Score for SM: -1.3544541131324062\n"
     ]
    }
   ],
   "source": [
    "def invert_wcm_1993_sigma_0(backscatter, params):\n",
    "    P1, P2, P3, P4, P5 = params\n",
    "\n",
    "    def residuals(x, obs_backscatter):\n",
    "        L, S = x  # L = LAI, S = SM\n",
    "        predicted = wcm_1993_sigma_0(P1, P2, P3, P4, P5, L, S)\n",
    "        return predicted - obs_backscatter\n",
    "\n",
    "    # Initial guesses for LAI and SM\n",
    "    initial_guess = [1.0, 0.2]  # Adjust based on expected ranges\n",
    "\n",
    "    # Bounds for LAI and SM\n",
    "    bounds = ([0, 0], [10, 1])  # LAI in [0, 10], SM in [0, 1]\n",
    "\n",
    "    # Store results\n",
    "    estimated_values = []\n",
    "\n",
    "    for obs_backscatter in backscatter:\n",
    "        result = least_squares(residuals, initial_guess, bounds=bounds, args=(obs_backscatter,))\n",
    "        if result.success:\n",
    "            estimated_values.append({\"LAI\": result.x[0], \"SM\": result.x[1]})\n",
    "        else:\n",
    "            estimated_values.append({\"LAI\": None, \"SM\": None})\n",
    "\n",
    "    return estimated_values\n",
    "\n",
    "\n",
    "# Example usage\n",
    "theta = np.deg2rad(40)  # Incidence angle in radians\n",
    "\n",
    "# Invert VV_dB to estimate SM and LAI\n",
    "inverted_values_vv = invert_wcm_1993_sigma_0(VV_dB, wcm_1993_params_vv)\n",
    "\n",
    "# Convert results to a DataFrame for better visualization\n",
    "inverted_df_vv = pd.DataFrame(inverted_values_vv)\n",
    "r2_lai = r2_score(LAI[:len(inverted_df_vv)], inverted_df_vv['LAI'].dropna())\n",
    "r2_sm = r2_score(SM[:len(inverted_df_vv)], inverted_df_vv['SM'].dropna())\n",
    "\n",
    "# Print the R2 scores\n",
    "print(f\"R2 Score for LAI: {r2_lai}\")\n",
    "print(f\"R2 Score for SM: {r2_sm}\")\n",
    "\n",
    "inverted_values_vh = invert_wcm_1993_sigma_0(VH_dB, wcm_1993_params_vh)\n",
    "\n",
    "# Convert results to a DataFrame for better visualization\n",
    "inverted_df_vh = pd.DataFrame(inverted_values_vh)\n",
    "r2_lai = r2_score(LAI[:len(inverted_df_vh)], inverted_df_vh['LAI'].dropna())\n",
    "r2_sm = r2_score(SM[:len(inverted_df_vh)], inverted_df_vh['SM'].dropna())\n",
    "\n",
    "# Print the R2 scores\n",
    "print(f\"R2 Score for LAI: {r2_lai}\")\n",
    "print(f\"R2 Score for SM: {r2_sm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e532fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_wcm_1993_sigma_0_VV_basin(polarization, L, S):\n",
    "    def residuals(params):\n",
    "        predicted = wcm_1993_sigma_0(*params, L, S)\n",
    "        residuals = predicted - polarization\n",
    "        return np.sum(residuals**2)  \n",
    "\n",
    "    initial_guess = [0.1, 1.3, 1.2, 0.9, 0.8]\n",
    "    result = basinhopping(residuals, initial_guess)\n",
    "    return result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4522e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For some reason basin Hopping REALLY DOES NOT LIKE THE FUNCTION\n",
    "#wcm_1993_validate_optimizer(optimize_wcm_1993_sigma_0_VV_basin, data_trimmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6eb315",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_wcm_1993_sigma_0_VV_de_hybrid(polarization, L, S):\n",
    "    def residuals(params):\n",
    "        predicted = wcm_1993_sigma_0(*params, L, S)\n",
    "        residuals = predicted - polarization\n",
    "        return np.sum(residuals**2)  \n",
    "\n",
    "    bounds = [(-10, 10), (-10, 10), (-10, 10), (-10, 10), (-10, 10)]  \n",
    "    result_de = differential_evolution(\n",
    "        residuals,\n",
    "        bounds,\n",
    "        maxiter=1000,  \n",
    "        popsize=20,    \n",
    "        tol=1e-6       \n",
    "    )\n",
    "    result_local = minimize(residuals, result_de.x, method='L-BFGS-B', bounds=bounds)\n",
    "    return result_local.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1704d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score For VV:0.31116239839870763\n",
      "R2 Score For VH:-0.27515464365877507\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((np.float64(-10.0),\n",
       "  np.float64(0.03729181058773102),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(2.549081516864716),\n",
       "  np.float64(-1.3383156202799733)),\n",
       " (np.float64(-7.046897309721912),\n",
       "  np.float64(-0.2379008222674929),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(0.7879750139291676)))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wcm_1993_validate_optimizer(optimize_wcm_1993_sigma_0_VV_de_hybrid, data_trimmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8586d678",
   "metadata": {},
   "source": [
    "Using OH for VV as model performs poorly with VV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3f414d",
   "metadata": {},
   "source": [
    "We will use Dubois Model Now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787ebd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dubois(P1, P2, P3, P4, theta, wavelength, sm, roughness):\n",
    "    return 10*np.log10(P1*np.power((np.sin(theta)/wavelength), P2)*np.power(sm, P3)*np.exp(P4*roughness))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d896a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dubois_validate_optimizer(optimizer_func, data):\n",
    "\n",
    "    params_VV = optimizer_func(VV_dB, theta, wavelength, SM, s)\n",
    "    predicted_VV = dubois(*params_VV, theta, wavelength, SM, s)\n",
    "\n",
    "    r2_VV = r2_score(VV_dB, predicted_VV)\n",
    "\n",
    "    params_VH = optimizer_func(VH_dB, theta, wavelength, SM, s)\n",
    "    predicted_VH = dubois(*params_VH, theta, wavelength, SM, s)\n",
    "\n",
    "    r2_VH = r2_score(VH_dB, predicted_VH)\n",
    "\n",
    "    clear_output()\n",
    "    print(f\"R2 Score For VV:{np.median(r2_VV)}\")\n",
    "    print(f\"R2 Score For VH:{np.median(r2_VH)}\")\n",
    "    return (predicted_VV, predicted_VH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19468820",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_dubois_ls(polarization, theta, wavelength, sm, roughness):\n",
    "    def residuals(params):\n",
    "        predicted = dubois(*params, theta=theta, wavelength=wavelength, sm=sm,  roughness=roughness)\n",
    "        residuals = predicted - polarization\n",
    "        if not np.all(np.isfinite(residuals)):\n",
    "            return np.inf\n",
    "        return residuals\n",
    "\n",
    "    initial_guess = [0.11, 0.7, 1.5, 0.2]\n",
    "    result = least_squares(residuals, initial_guess, method='trf', loss='soft_l1', max_nfev=10000)\n",
    "    return result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95f7851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score For VV:0.6287818446187787\n",
      "R2 Score For VH:0.6406736694654751\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ -9.85370021,  -9.98654847,  -9.92417675, -10.12840596,\n",
       "        -10.01114385,  -9.1560243 ,  -8.80059455,  -9.01530855,\n",
       "         -8.31733723,  -7.42402627]),\n",
       " array([-17.94841317, -18.15848405, -18.05985663, -18.38280109,\n",
       "        -18.19737635, -16.84518913, -16.28315362, -16.62267751,\n",
       "        -15.51898635, -14.10640766]))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dubois_validate_optimizer(optimize_dubois_ls, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c71ce9",
   "metadata": {},
   "source": [
    "Combining Dubois Model with WCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31c9fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wcm_dubois(P1, P2, P5, P6, P7, P8, P9, L, S, theta, wavelength, roughness):\n",
    "    # P5 > 0\n",
    "    t2 = np.exp(-2 * P2 * L / np.cos(theta))\n",
    "    sigma_veg = P1 * np.power(L, P5) * np.cos(theta)  # * (1 - t2) #Including the (1-t2) gets less r2_Score what???\n",
    "    sigma_soil = 10 * np.log10(P6 * np.power((np.sin(theta) / wavelength), P7) * np.power(S, P8) * np.exp(P9 * roughness))\n",
    "    return sigma_veg + (t2 * sigma_soil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56910af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wcm_dubois_validate_optimizer(optimizer_func):\n",
    "\n",
    "    params_VV = optimizer_func(VV_dB, LAI, SM, theta, wavelength, s)\n",
    "    predicted_VV = wcm_dubois(*params_VV, LAI, SM, theta, wavelength, s)\n",
    "\n",
    "    r2_VV = r2_score(VV_dB, predicted_VV)\n",
    "\n",
    "    params_VH = optimizer_func(VH_dB, LAI, SM, theta, wavelength, s)\n",
    "    predicted_VH = wcm_dubois(*params_VH, LAI, SM, theta, wavelength, s)\n",
    "\n",
    "    r2_VH = r2_score(VH_dB, predicted_VH)\n",
    "\n",
    "    clear_output()\n",
    "    print(f\"R2 Score For VV:{np.median(r2_VV)}\")\n",
    "    print(f\"R2 Score For VH:{np.median(r2_VH)}\")\n",
    "    return (predicted_VV, predicted_VH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d084e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_optimizer_wcm_dubois(optimizer_func):\n",
    "    params_VV = optimizer_func(VV_dB, LAI, SM, theta, wavelength, s)\n",
    "    predicted_VV = wcm_dubois(*params_VV, LAI, SM, theta, wavelength, s)\n",
    "    r2_VV = r2_score(VV_dB, predicted_VV)\n",
    "\n",
    "    params_VH = optimizer_func(VH_dB, LAI, SM, theta, wavelength, s)\n",
    "    predicted_VH = wcm_dubois(*params_VH, LAI, SM, theta, wavelength, s)\n",
    "    r2_VH = r2_score(VH_dB, predicted_VH)\n",
    "    \n",
    "    clear_output()\n",
    "    print(f\"R2 Score For VV:{np.median(r2_VV)}\")\n",
    "    print(f\"R2 Score For VH:{np.median(r2_VH)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b458c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_wcm_dubois_ls(polarization, L, S, theta, wavelength, roughness):\n",
    "    def residuals(params):\n",
    "        try:\n",
    "            predicted = wcm_dubois(*params, L, S, theta, wavelength, roughness)\n",
    "            residuals = predicted - polarization\n",
    "            if not np.all(np.isfinite(residuals)):\n",
    "                return np.inf\n",
    "            return residuals\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            return np.inf\n",
    "\n",
    "    initial_guess = [1]*7\n",
    "    result = least_squares(residuals, initial_guess, method='trf', loss='soft_l1', max_nfev=10000)\n",
    "    return result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568eaba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score For VV:0.7668881918837822\n",
      "R2 Score For VH:0.7229084449648002\n"
     ]
    }
   ],
   "source": [
    "validate_optimizer_wcm_dubois(optimize_wcm_dubois_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae48608",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_wcm_dubois_de_hybrid(polarization, L, S, theta, wavelength, roughness):\n",
    "    def residuals(params):\n",
    "        try:\n",
    "            predicted = wcm_dubois(*params, L, S, theta, wavelength, roughness)\n",
    "            residuals = predicted - polarization\n",
    "            if not np.all(np.isfinite(residuals)):\n",
    "                return np.inf\n",
    "            return np.sum(residuals**2)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            return np.inf\n",
    "    \n",
    "    bounds = [(-10,10)]*7 \n",
    "    result_de = differential_evolution(\n",
    "        residuals,\n",
    "        bounds,\n",
    "        maxiter=1000,  \n",
    "        popsize=20,    \n",
    "        tol=1e-6       \n",
    "    )\n",
    "    result_local = minimize(residuals, result_de.x, method='L-BFGS-B', bounds=bounds)\n",
    "    return result_local.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ab02d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score For VV:0.7677554860618603\n",
      "R2 Score For VH:0.7054043004037527\n"
     ]
    }
   ],
   "source": [
    "validate_optimizer_wcm_dubois(optimize_wcm_dubois_de_hybrid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9aeedd4",
   "metadata": {},
   "source": [
    "OH 2004 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831c9a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oh_2004_backscatter(P1, P2, P3, P4, P5, P6, P7, P8, theta, roughness, wavelength, sm):\n",
    "    epsilon_r = P1+P2*sm+P3*(sm**2)+P4*(sm**3)\n",
    "    cos_theta = np.cos(theta)\n",
    "\n",
    "    sigma0_linear = P5 * (cos_theta ** P6) * ((roughness / wavelength) ** P7) * (epsilon_r ** P8)\n",
    "    sigma0_dB = 10 * np.log10(sigma0_linear)\n",
    "\n",
    "    return sigma0_dB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda694e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_optimizer_oh_2004(optimizer_func):\n",
    "    \n",
    "    params_VV = optimizer_func(VV_dB, theta, s, wavelength, SM)\n",
    "    predicted_VV = oh_2004_backscatter(*params_VV, theta, s, wavelength, SM)\n",
    "    r2_VV = r2_score(VV_dB, predicted_VV)\n",
    "    \n",
    "    params_VH = optimizer_func(VH_dB, theta, s, wavelength, SM)\n",
    "    predicted_VH = oh_2004_backscatter(*params_VH, theta, s, wavelength, SM)\n",
    "    r2_VH = r2_score(VH_dB, predicted_VH)\n",
    "    \n",
    "    \n",
    "    \n",
    "    clear_output()\n",
    "    print(f\"R2 Score For VV:{np.median(r2_VV)}\")\n",
    "    print(f\"R2 Score For VH:{np.median(r2_VH)}\")\n",
    "    print(params_VH)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ea62b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_oh_2004_ls(polarization, theta, roughness, wavelength, sm):\n",
    "    def residuals(params):\n",
    "        try:\n",
    "            predicted = oh_2004_backscatter(*params, theta, roughness, wavelength, sm)\n",
    "            residuals = predicted - polarization\n",
    "            if not np.all(np.isfinite(residuals)):\n",
    "                return np.inf\n",
    "            return residuals\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            return np.inf\n",
    "        \n",
    "    initial_guess = [0.1] * 8\n",
    "    result = least_squares(residuals, initial_guess, method='trf', loss='soft_l1', max_nfev=10000)\n",
    "    return result.x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390adf35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score For VV:0.7110606216015922\n",
      "R2 Score For VH:0.6416740190929665\n",
      "[ 0.03501365 -0.55176648  2.76151426 -4.19572099  0.41439392  0.10048917\n",
      "  0.12901702  0.36830767]\n"
     ]
    }
   ],
   "source": [
    "validate_optimizer_oh_2004(optimize_oh_2004_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce71e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_oh_2004_de_hybrid(polarization, theta, roughness, wavelength, sm):\n",
    "    def residuals(params):\n",
    "        try:\n",
    "            predicted = oh_2004_backscatter(*params, theta, roughness, wavelength, sm)\n",
    "            residuals = predicted - polarization\n",
    "            if not np.all(np.isfinite(residuals)):\n",
    "                return np.inf\n",
    "            return np.sum(residuals**2)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            return np.inf\n",
    "\n",
    "    bounds = [(-50,50)] * 4 + [(-10,10)] * 4\n",
    "    result_de = differential_evolution(\n",
    "        residuals,\n",
    "        bounds,\n",
    "        strategy='rand1bin',  # Alternative strategy\n",
    "        maxiter=2000,         # Increase iterations\n",
    "        popsize=30,           # Larger population size\n",
    "        mutation=(0.5, 1.5),  # Wider mutation range\n",
    "        recombination=0.9,    # Higher crossover probability\n",
    "        tol=1e-8              # Tighter convergence tolerance\n",
    "    )\n",
    "    result_local = minimize(residuals, result_de.x, method='L-BFGS-B', bounds=bounds)\n",
    "    return result_local.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196ba2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mayur\\AppData\\Local\\Temp\\ipykernel_13232\\3285965954.py:5: RuntimeWarning: invalid value encountered in power\n",
      "  sigma0_linear = P5 * (cos_theta ** P6) * ((roughness / wavelength) ** P7) * (epsilon_r ** P8)\n",
      "C:\\Users\\Mayur\\AppData\\Local\\Temp\\ipykernel_13232\\3285965954.py:6: RuntimeWarning: invalid value encountered in log10\n",
      "  sigma0_dB = 10 * np.log10(sigma0_linear)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[130]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mvalidate_optimizer_oh_2004\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimize_oh_2004_de_hybrid\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[126]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mvalidate_optimizer_oh_2004\u001b[39m\u001b[34m(optimizer_func)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvalidate_optimizer_oh_2004\u001b[39m(optimizer_func):\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     params_VV = \u001b[43moptimizer_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mVV_dB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwavelength\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSM\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     predicted_VV = oh_2004_backscatter(*params_VV, theta, s, wavelength, SM)\n\u001b[32m      5\u001b[39m     r2_VV = r2_score(VV_dB, predicted_VV)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[129]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36moptimize_oh_2004_de_hybrid\u001b[39m\u001b[34m(polarization, theta, roughness, wavelength, sm)\u001b[39m\n\u001b[32m     11\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m np.inf\n\u001b[32m     13\u001b[39m bounds = [(-\u001b[32m50\u001b[39m,\u001b[32m50\u001b[39m)] * \u001b[32m4\u001b[39m + [(-\u001b[32m10\u001b[39m,\u001b[32m10\u001b[39m)] * \u001b[32m4\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m result_de = \u001b[43mdifferential_evolution\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresiduals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrand1bin\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Alternative strategy\u001b[39;49;00m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;66;43;03m# Increase iterations\u001b[39;49;00m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpopsize\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;66;43;03m# Larger population size\u001b[39;49;00m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmutation\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1.5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Wider mutation range\u001b[39;49;00m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrecombination\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Higher crossover probability\u001b[39;49;00m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-8\u001b[39;49m\u001b[43m              \u001b[49m\u001b[38;5;66;43;03m# Tighter convergence tolerance\u001b[39;49;00m\n\u001b[32m     23\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m result_local = minimize(residuals, result_de.x, method=\u001b[33m'\u001b[39m\u001b[33mL-BFGS-B\u001b[39m\u001b[33m'\u001b[39m, bounds=bounds)\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result_local.x\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Mayur\\Documents\\College\\4th sem\\Exploratory\\.venv\\Lib\\site-packages\\scipy\\_lib\\_util.py:440\u001b[39m, in \u001b[36m_transition_to_rng.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    433\u001b[39m     message = (\n\u001b[32m    434\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe NumPy global RNG was seeded by calling \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    435\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`np.random.seed`. Beginning in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, this \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    436\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mfunction will no longer use the global RNG.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    437\u001b[39m     ) + cmn_msg\n\u001b[32m    438\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m440\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Mayur\\Documents\\College\\4th sem\\Exploratory\\.venv\\Lib\\site-packages\\scipy\\optimize\\_differentialevolution.py:501\u001b[39m, in \u001b[36mdifferential_evolution\u001b[39m\u001b[34m(func, bounds, args, strategy, maxiter, popsize, tol, mutation, recombination, rng, callback, disp, polish, init, atol, updating, workers, constraints, x0, integrality, vectorized)\u001b[39m\n\u001b[32m    484\u001b[39m \u001b[38;5;66;03m# using a context manager means that any created Pool objects are\u001b[39;00m\n\u001b[32m    485\u001b[39m \u001b[38;5;66;03m# cleared up.\u001b[39;00m\n\u001b[32m    486\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m DifferentialEvolutionSolver(func, bounds, args=args,\n\u001b[32m    487\u001b[39m                                  strategy=strategy,\n\u001b[32m    488\u001b[39m                                  maxiter=maxiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m    499\u001b[39m                                  integrality=integrality,\n\u001b[32m    500\u001b[39m                                  vectorized=vectorized) \u001b[38;5;28;01mas\u001b[39;00m solver:\n\u001b[32m--> \u001b[39m\u001b[32m501\u001b[39m     ret = \u001b[43msolver\u001b[49m\u001b[43m.\u001b[49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    503\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Mayur\\Documents\\College\\4th sem\\Exploratory\\.venv\\Lib\\site-packages\\scipy\\optimize\\_differentialevolution.py:1185\u001b[39m, in \u001b[36mDifferentialEvolutionSolver.solve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1182\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m nit \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.maxiter + \u001b[32m1\u001b[39m):\n\u001b[32m   1183\u001b[39m     \u001b[38;5;66;03m# evolve the population by a generation\u001b[39;00m\n\u001b[32m   1184\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1185\u001b[39m         \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1186\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m   1187\u001b[39m         warning_flag = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Mayur\\Documents\\College\\4th sem\\Exploratory\\.venv\\Lib\\site-packages\\scipy\\optimize\\_differentialevolution.py:1579\u001b[39m, in \u001b[36mDifferentialEvolutionSolver.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1576\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[32m   1578\u001b[39m \u001b[38;5;66;03m# create a trial solution\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1579\u001b[39m trial = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mutate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcandidate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1581\u001b[39m \u001b[38;5;66;03m# ensuring that it's in the range [0, 1)\u001b[39;00m\n\u001b[32m   1582\u001b[39m \u001b[38;5;28mself\u001b[39m._ensure_constraint(trial)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Mayur\\Documents\\College\\4th sem\\Exploratory\\.venv\\Lib\\site-packages\\scipy\\optimize\\_differentialevolution.py:1769\u001b[39m, in \u001b[36mDifferentialEvolutionSolver._mutate\u001b[39m\u001b[34m(self, candidate)\u001b[39m\n\u001b[32m   1766\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1767\u001b[39m     bprime = \u001b[38;5;28mself\u001b[39m.mutation_func(samples)\n\u001b[32m-> \u001b[39m\u001b[32m1769\u001b[39m crossovers = \u001b[43mrng\u001b[49m\u001b[43m.\u001b[49m\u001b[43muniform\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparameter_count\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1770\u001b[39m crossovers = crossovers < \u001b[38;5;28mself\u001b[39m.cross_over_probability\n\u001b[32m   1771\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.strategy \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._binomial:\n\u001b[32m   1772\u001b[39m     \u001b[38;5;66;03m# the last one is always from the bprime vector for binomial\u001b[39;00m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;66;03m# If you fill in modulo with a loop you have to set the last one to\u001b[39;00m\n\u001b[32m   1774\u001b[39m     \u001b[38;5;66;03m# true. If you don't use a loop then you can have any random entry\u001b[39;00m\n\u001b[32m   1775\u001b[39m     \u001b[38;5;66;03m# be True.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "validate_optimizer_oh_2004(optimize_oh_2004_de_hybrid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
