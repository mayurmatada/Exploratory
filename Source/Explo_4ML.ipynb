{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e92ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4ade9e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\Mayur\\Documents\\College\\4th sem\\Exploratory\\Data\\Sentinel1_MODIS_SM_Masked_Urban_YellowRiver_11km.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "826e1b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "IncidenceAngle",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "LAI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "SoilMoisture",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "VH",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "VV",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Month_Sin",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Month_Cos",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Day_Sin",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Day_Cos",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "10ac7165-9051-4a71-adb6-d2d46365fadf",
       "rows": [
        [
         "0",
         "4.172704011342524",
         "0.3729366848831541",
         "-0.9265071727946046",
         "-0.31637203718561924",
         "0.7756376352897817",
         "1.2246467991473532e-16",
         "-1.0",
         "0.8660254037844386",
         "0.5000000000000001"
        ],
        [
         "1",
         "3.552232161220396",
         "0.5003319920047917",
         "-1.2886831288449987",
         "0.9196167458717631",
         "0.9986191841572506",
         "1.2246467991473532e-16",
         "-1.0",
         "-0.4067366430757998",
         "-0.9135454576426011"
        ],
        [
         "2",
         "3.5533972506885205",
         "0.6219523622148658",
         "-0.3261034976298643",
         "4.863160646341608",
         "3.679401323376806",
         "1.2246467991473532e-16",
         "-1.0",
         "-0.20791169081775987",
         "0.9781476007338056"
        ],
        [
         "3",
         "3.5527461223266448",
         "1.0934478839310922",
         "-0.5631241492405403",
         "0.8894926359608931",
         "1.0935523902362339",
         "-0.5000000000000001",
         "-0.8660254037844386",
         "0.7431448254773945",
         "-0.6691306063588579"
        ],
        [
         "4",
         "4.595356714429633",
         "1.166351545162296",
         "-0.8052351806128621",
         "0.6510933166280252",
         "0.7536000228565286",
         "-0.5000000000000001",
         "-0.8660254037844386",
         "-0.20791169081775907",
         "-0.9781476007338057"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IncidenceAngle</th>\n",
       "      <th>LAI</th>\n",
       "      <th>SoilMoisture</th>\n",
       "      <th>VH</th>\n",
       "      <th>VV</th>\n",
       "      <th>Month_Sin</th>\n",
       "      <th>Month_Cos</th>\n",
       "      <th>Day_Sin</th>\n",
       "      <th>Day_Cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.172704</td>\n",
       "      <td>0.372937</td>\n",
       "      <td>-0.926507</td>\n",
       "      <td>-0.316372</td>\n",
       "      <td>0.775638</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.552232</td>\n",
       "      <td>0.500332</td>\n",
       "      <td>-1.288683</td>\n",
       "      <td>0.919617</td>\n",
       "      <td>0.998619</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.406737</td>\n",
       "      <td>-0.913545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.553397</td>\n",
       "      <td>0.621952</td>\n",
       "      <td>-0.326103</td>\n",
       "      <td>4.863161</td>\n",
       "      <td>3.679401</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.207912</td>\n",
       "      <td>0.978148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.552746</td>\n",
       "      <td>1.093448</td>\n",
       "      <td>-0.563124</td>\n",
       "      <td>0.889493</td>\n",
       "      <td>1.093552</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.743145</td>\n",
       "      <td>-0.669131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.595357</td>\n",
       "      <td>1.166352</td>\n",
       "      <td>-0.805235</td>\n",
       "      <td>0.651093</td>\n",
       "      <td>0.753600</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.207912</td>\n",
       "      <td>-0.978148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IncidenceAngle       LAI  SoilMoisture        VH        VV     Month_Sin  \\\n",
       "0        4.172704  0.372937     -0.926507 -0.316372  0.775638  1.224647e-16   \n",
       "1        3.552232  0.500332     -1.288683  0.919617  0.998619  1.224647e-16   \n",
       "2        3.553397  0.621952     -0.326103  4.863161  3.679401  1.224647e-16   \n",
       "3        3.552746  1.093448     -0.563124  0.889493  1.093552 -5.000000e-01   \n",
       "4        4.595357  1.166352     -0.805235  0.651093  0.753600 -5.000000e-01   \n",
       "\n",
       "   Month_Cos   Day_Sin   Day_Cos  \n",
       "0  -1.000000  0.866025  0.500000  \n",
       "1  -1.000000 -0.406737 -0.913545  \n",
       "2  -1.000000 -0.207912  0.978148  \n",
       "3  -0.866025  0.743145 -0.669131  \n",
       "4  -0.866025 -0.207912 -0.978148  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_data(data):\n",
    "    # Drop rows with missing data in columns: 'LAI', 'SoilMoisture' and 3 other columns\n",
    "    data = data.dropna(subset=['LAI', 'SoilMoisture', 'VH', 'VV', 'date'])\n",
    "    # Group by 'date' and calculate the average of numeric columns\n",
    "    data = data.groupby('date').mean(numeric_only=True).reset_index()\n",
    "    # Drop column: 'SoilRoughness_placeholder'\n",
    "    data = data.drop(columns=['SoilRoughness_placeholder'])\n",
    "    # Drop column: 'Frequency_GHz'\n",
    "    data = data.drop(columns=['Frequency_GHz'])\n",
    "    # Extract year, month, and day from the 'date' column\n",
    "    data['Year'] = pd.to_datetime(data['date']).dt.year\n",
    "    data['Month'] = pd.to_datetime(data['date']).dt.month\n",
    "    data['Day'] = pd.to_datetime(data['date']).dt.day\n",
    "    # Drop column: 'date'\n",
    "    data = data.drop(columns=['date'])\n",
    "    # Drop column: 'Year'\n",
    "    data = data.drop(columns=['Year'])\n",
    "    # Convert Month and Day columns to numeric\n",
    "    data['Month'] = pd.to_numeric(data['Month'], errors='coerce')\n",
    "    data['Day'] = pd.to_numeric(data['Day'], errors='coerce')\n",
    "    # Add two new columns for Sin and Cos transformations of Month\n",
    "    data['Month_Sin'] = np.sin(2 * np.pi * (data['Month'] / 12))\n",
    "    data['Month_Cos'] = np.cos(2 * np.pi * (data['Month'] / 12))\n",
    "    # Add sin and cos transformations of Day\n",
    "    data['Day_Sin'] = np.sin(2 * np.pi * (data['Day'] / 30))\n",
    "    data['Day_Cos'] = np.cos(2 * np.pi * (data['Day'] / 30))\n",
    "    # Drop column: 'Day'\n",
    "    data = data.drop(columns=['Day'])\n",
    "    # Drop column: 'Month'\n",
    "    data = data.drop(columns=['Month'])\n",
    "    # Convert VV and VH from decibels to linear\n",
    "    data['VV'] = 10 ** (data['VV'] / 10)\n",
    "    data['VH'] = 10 ** (data['VH'] / 10)\n",
    "    # Scale VV and VH normally\n",
    "    scaler_vv_vh = StandardScaler()\n",
    "    data[['VV', 'VH']] = scaler_vv_vh.fit_transform(data[['VV', 'VH']])\n",
    "    # Scale SoilMoisture normally\n",
    "    scaler_sm = StandardScaler()\n",
    "    data['SoilMoisture'] = scaler_sm.fit_transform(data[['SoilMoisture']])\n",
    "    # Scale IncidenceAngle with 1/10 importance of SoilMoisture\n",
    "    data['IncidenceAngle'] = data['IncidenceAngle'] * 0.1 / data['SoilMoisture'].std()\n",
    "    # Scale LAI with 0.75 importance of SoilMoisture\n",
    "    data['LAI'] = data['LAI'] * 0.75 / data['SoilMoisture'].std()\n",
    "    # Sin and Cos columns remain unchanged\n",
    "    # (No operation needed for Month_Sin, Month_Cos, Day_Sin, Day_Cos)\n",
    "    # Ensure the result is a DataFrame\n",
    "    data = pd.DataFrame(data)\n",
    "    return data\n",
    "\n",
    "data_clean = clean_data(data.copy())\n",
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "de5bd380",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['VV', 'VH', 'IncidenceAngle', 'Month_Sin', 'Month_Cos', 'Day_Sin', 'Day_Cos']\n",
    "target_cols = ['LAI', 'SoilMoisture']\n",
    "\n",
    "X = data_clean[feature_cols].values\n",
    "y = data_clean[target_cols].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16bf75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - LAI R²: 0.5205, SM R²: 0.0650\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "r2_lai = r2_score(y_test[:, 0], y_pred[:, 0])\n",
    "r2_sm = r2_score(y_test[:, 1], y_pred[:, 1])\n",
    "\n",
    "print(f\"Random Forest - LAI R²: {r2_lai:.4f}, SM R²: {r2_sm:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e3adf4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP — LAI R²: 0.4811, SM R²: -0.4191\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPRegressor(hidden_layer_sizes=(64, 32), max_iter=5000, random_state=42)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "r2_lai = r2_score(y_test[:, 0], y_pred[:, 0])\n",
    "r2_sm = r2_score(y_test[:, 1], y_pred[:, 1])\n",
    "\n",
    "print(f\"MLP — LAI R²: {r2_lai:.4f}, SM R²: {r2_sm:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ff363bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble — LAI R²: 0.5576, SM R²: -0.3671\n",
      "Predictive std (first few): [[0.38931538 0.66225983]\n",
      " [0.24770027 0.91559111]\n",
      " [0.16370809 0.28241463]\n",
      " [0.30019186 0.35639699]\n",
      " [0.17563445 0.14012996]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "\n",
    "def train_ensemble(X_train, y_train, n_models=5):\n",
    "    ensemble = []\n",
    "    for _ in range(n_models):\n",
    "        X_res, y_res = resample(X_train, y_train)\n",
    "        model = MLPRegressor(hidden_layer_sizes=(64, 32), max_iter=2000, random_state=None)\n",
    "        model.fit(X_res, y_res)\n",
    "        ensemble.append(model)\n",
    "    return ensemble\n",
    "\n",
    "\n",
    "def ensemble_predict(models, X):\n",
    "    preds = np.array([m.predict(X) for m in models])\n",
    "    return preds.mean(axis=0), preds.std(axis=0)\n",
    "\n",
    "\n",
    "ensemble = train_ensemble(X_train, y_train, n_models=10)\n",
    "y_mean, y_std = ensemble_predict(ensemble, X_test)\n",
    "\n",
    "r2_lai = r2_score(y_test[:, 0], y_mean[:, 0])\n",
    "r2_sm = r2_score(y_test[:, 1], y_mean[:, 1])\n",
    "\n",
    "print(f\"Ensemble — LAI R²: {r2_lai:.4f}, SM R²: {r2_sm:.4f}\")\n",
    "print(\"Predictive std (first few):\", y_std[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a4e788",
   "metadata": {},
   "source": [
    "Monte Carlo Dropout with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4775b62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCDropoutMLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, dropout_rate=0.2):\n",
    "        super(MCDropoutMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.out = nn.Linear(32, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)  # Dropout ON during train and test\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        return self.out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4af046ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to torch tensors\n",
    "X_train_torch = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_torch = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_torch = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_torch = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_train_torch, y_train_torch), batch_size=16, shuffle=True)\n",
    "\n",
    "model = MCDropoutMLP(input_dim=X.shape[1], output_dim=2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Train\n",
    "for epoch in range(300):\n",
    "    for xb, yb in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(model(xb), yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3022219a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC Dropout PyTorch — LAI R²: 0.5576, SM R²: -0.3671\n",
      "Predictive std (first few):\n",
      " [[0.38931538 0.66225983]\n",
      " [0.24770027 0.91559111]\n",
      " [0.16370809 0.28241463]\n",
      " [0.30019186 0.35639699]\n",
      " [0.17563445 0.14012996]]\n"
     ]
    }
   ],
   "source": [
    "r2_lai = r2_score(y_test[:, 0], y_mean[:, 0])\n",
    "r2_sm = r2_score(y_test[:, 1], y_mean[:, 1])\n",
    "\n",
    "print(f\"MC Dropout PyTorch — LAI R²: {r2_lai:.4f}, SM R²: {r2_sm:.4f}\")\n",
    "print(\"Predictive std (first few):\\n\", y_std[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "93a51ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_tensor shape: torch.Size([362, 7])\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train_tensor shape: {X_train_torch.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "7cbfb739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Loss: 0.8619\n",
      "Epoch [20/50], Loss: 0.7954\n",
      "Epoch [30/50], Loss: 0.7719\n",
      "Epoch [40/50], Loss: 0.7594\n",
      "Epoch [50/50], Loss: 0.7502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mayur\\Documents\\College\\4th sem\\Exploratory\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:610: UserWarning: Using a target size (torch.Size([362, 2])) that is different to the input size (torch.Size([362, 1, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, (hn, cn) = self.lstm(x)\n",
    "        out = self.fc(lstm_out[:, -1, :])  # Take the output from the last time step\n",
    "        return out\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = 7  # Number of input features\n",
    "hidden_size = 64\n",
    "output_size = 2  # Predicting LAI or SM\n",
    "\n",
    "# Example input (batch_size=362, seq_len=7, input_size=7)\n",
    "X_train_tensor = X_train_torch\n",
    "X_train_tensor = X_train_tensor.unsqueeze(1)  # Add a sequence dimension\n",
    "y_train_tensor = y_train_torch \n",
    "\n",
    "# Model, loss, optimizer\n",
    "LSTM_model = LSTMModel(input_size, hidden_size, output_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "4dd463bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Model R^2: -0.7460\n"
     ]
    }
   ],
   "source": [
    "LSTM_model.eval()  # Switch to evaluation mode\n",
    "with torch.no_grad():\n",
    "    # Example for inference\n",
    "    y_pred_lstm = LSTM_model(X_test_torch.unsqueeze(1))  # X_test_tensor is your test data\n",
    "    y_true = y_test_torch  # Actual values of LAI or SM\n",
    "\n",
    "# Calculate R2 score\n",
    "r2_lstm = r2_score(y_test_torch, (y_pred_lstm.numpy()))\n",
    "print(f\"LSTM Model R^2: {r2_lstm:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "dc46e2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], D Loss: 1.3432, G Loss: 0.6777\n",
      "Epoch [20/50], D Loss: 1.3215, G Loss: 0.6679\n",
      "Epoch [30/50], D Loss: 1.3055, G Loss: 0.6598\n",
      "Epoch [40/50], D Loss: 1.2834, G Loss: 0.6568\n",
      "Epoch [50/50], D Loss: 1.2425, G Loss: 0.6706\n"
     ]
    }
   ],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_dim, output_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc1 = nn.Linear(noise_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, output_dim)\n",
    "\n",
    "    def forward(self, z):\n",
    "        z = torch.relu(self.fc1(z))\n",
    "        z = torch.relu(self.fc2(z))\n",
    "        return torch.tanh(self.fc3(z))\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 128)\n",
    "        self.fc3 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return torch.sigmoid(self.fc3(x))\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "noise_dim = 100\n",
    "input_dim = 7  # Assuming we're generating input features like LAI or SM\n",
    "lr = 0.0002\n",
    "\n",
    "# Initialize models\n",
    "generator = Generator(noise_dim, input_dim)\n",
    "discriminator = Discriminator(input_dim)\n",
    "\n",
    "# Loss and optimizers\n",
    "criterion = nn.BCELoss()\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "# Training loop for GAN\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    # Train Discriminator\n",
    "    real_data = torch.randn(32, input_dim)  # Real data (e.g., from dataset)\n",
    "    fake_data = generator(torch.randn(32, noise_dim))\n",
    "\n",
    "    optimizer_D.zero_grad()\n",
    "    real_loss = criterion(discriminator(real_data), torch.ones(32, 1))\n",
    "    fake_loss = criterion(discriminator(fake_data.detach()), torch.zeros(32, 1))\n",
    "    d_loss = real_loss + fake_loss\n",
    "    d_loss.backward()\n",
    "    optimizer_D.step()\n",
    "\n",
    "    # Train Generator\n",
    "    optimizer_G.zero_grad()\n",
    "    g_loss = criterion(discriminator(fake_data), torch.ones(32, 1))\n",
    "    g_loss.backward()\n",
    "    optimizer_G.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{epochs}], D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
