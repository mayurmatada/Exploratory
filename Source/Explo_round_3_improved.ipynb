{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Water Cloud Model (WCM) and Dubois Model Implementation\n",
    "\n",
    "This notebook implements and evaluates the Water Cloud Model (Prevot, 1993) and Dubois Model for radar backscatter estimation using Sentinel-1 data.\n",
    "\n",
    "The main objectives are:\n",
    "1. Implement the WCM model for VV and VH polarizations\n",
    "2. Optimize model parameters using different optimization techniques\n",
    "3. Evaluate model performance using R² score\n",
    "4. Implement ML model stacking to improve predictions\n",
    "5. Compare with the Dubois model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Machine learning and optimization\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import KFold, train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Optimization methods\n",
    "from scipy.optimize import least_squares, basinhopping, differential_evolution, minimize\n",
    "import scipy.constants\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Utilities\n",
    "from IPython.display import clear_output\n",
    "from functools import partial\n",
    "import warnings\n",
    "\n",
    "# Ignore warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Constants\n",
    "\n",
    "These constants are used in the radar backscatter models:\n",
    "- f: Frequency (5.4 GHz for Sentinel-1)\n",
    "- c: Speed of light\n",
    "- wavelength: Wavelength calculated from frequency\n",
    "- k: Wave number\n",
    "- s: Surface roughness parameter\n",
    "- sbl: Another surface roughness parameter\n",
    "- theta: Incidence angle in degrees\n",
    "- theta_rad: Incidence angle in radians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Radar parameters\n",
    "f = 5.4e9  # Frequency in Hz (5.4 GHz for Sentinel-1)\n",
    "c = scipy.constants.c  # Speed of light\n",
    "wavelength = c / f  # Wavelength in meters\n",
    "k = 2 * np.pi * f / c  # Wave number\n",
    "\n",
    "# Surface parameters\n",
    "s = 0.0097  # Surface roughness parameter\n",
    "sbl = 0.013  # Another surface roughness parameter\n",
    "\n",
    "# Incidence angle\n",
    "theta = 40  # Degrees\n",
    "theta_rad = np.deg2rad(theta)  # Radians\n",
    "\n",
    "# Display constants for reference\n",
    "print(f\"Frequency: {f/1e9} GHz\")\n",
    "print(f\"Wavelength: {wavelength:.4f} m\")\n",
    "print(f\"Incidence angle: {theta}° ({theta_rad:.4f} rad)\")\n",
    "print(f\"Surface roughness (s): {s}\")\n",
    "print(f\"Surface roughness (sbl): {sbl}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Preprocess Data\n",
    "\n",
    "We load the dataset containing:\n",
    "- VV: Vertical-Vertical polarization backscatter (dB)\n",
    "- VH: Vertical-Horizontal polarization backscatter (dB)\n",
    "- SM: Soil Moisture\n",
    "- LAI: Leaf Area Index\n",
    "\n",
    "The data is trimmed to remove outliers based on standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv(r\"../Data/Merged_Data.csv\")\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"Dataset shape:\", data.shape)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(data.head())\n",
    "\n",
    "print(\"\\nBasic statistics:\")\n",
    "display(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distributions of key variables\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "sns.histplot(data['VV'], kde=True, ax=axes[0, 0])\n",
    "axes[0, 0].set_title('VV Distribution')\n",
    "\n",
    "sns.histplot(data['VH'], kde=True, ax=axes[0, 1])\n",
    "axes[0, 1].set_title('VH Distribution')\n",
    "\n",
    "sns.histplot(data['SM'], kde=True, ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Soil Moisture Distribution')\n",
    "\n",
    "sns.histplot(data['LAI'], kde=True, ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Leaf Area Index Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize relationships between variables\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.pairplot(data[['VV', 'VH', 'SM', 'LAI']])\n",
    "plt.suptitle('Pairwise Relationships Between Variables', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to trim outliers based on standard deviation\n",
    "def trim_outliers(df, column, n_std=4):\n",
    "    \"\"\"Trim outliers from a dataframe based on standard deviation.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing the data\n",
    "        column: Column name to trim outliers from\n",
    "        n_std: Number of standard deviations to use as threshold\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with outliers removed\n",
    "    \"\"\"\n",
    "    mean = df[column].mean()\n",
    "    std = df[column].std()\n",
    "    return df[(df[column] >= mean - n_std * std) & (df[column] <= mean + n_std * std)]\n",
    "\n",
    "# Trim outliers for VV and VH\n",
    "trim_number = 4  # Number of standard deviations to use as threshold\n",
    "data_trimmed = data.copy()\n",
    "data_trimmed = trim_outliers(data_trimmed, 'VV', trim_number)\n",
    "data_trimmed = trim_outliers(data_trimmed, 'VH', trim_number)\n",
    "\n",
    "print(f\"Original data shape: {data.shape}\")\n",
    "print(f\"Trimmed data shape: {data_trimmed.shape}\")\n",
    "print(f\"Removed {data.shape[0] - data_trimmed.shape[0]} rows ({(data.shape[0] - data_trimmed.shape[0])/data.shape[0]*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data for modeling\n",
    "segment = 0  # Segment of data to use (0 means first segment)\n",
    "segment_size = 41  # Size of each segment\n",
    "\n",
    "# If segment is 0, use all data instead of slicing\n",
    "if segment == 0 and segment_size >= len(data_trimmed):\n",
    "    VV_dB = data_trimmed['VV'].values\n",
    "    VH_dB = data_trimmed['VH'].values\n",
    "    SM = data_trimmed['SM'].values\n",
    "    LAI = data_trimmed['LAI'].values\n",
    "else:\n",
    "    # Extract segment\n",
    "    start_idx = segment * segment_size\n",
    "    end_idx = min(start_idx + segment_size, len(data_trimmed))\n",
    "    \n",
    "    VV_dB = data_trimmed['VV'].values[start_idx:end_idx]\n",
    "    VH_dB = data_trimmed['VH'].values[start_idx:end_idx]\n",
    "    SM = data_trimmed['SM'].values[start_idx:end_idx]\n",
    "    LAI = data_trimmed['LAI'].values[start_idx:end_idx]\n",
    "\n",
    "# Convert from dB to linear scale\n",
    "VV_linear = 10**(VV_dB / 10)\n",
    "VH_linear = 10**(VH_dB / 10)\n",
    "\n",
    "print(f\"Data shape after segmentation: {len(VV_dB)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Water Cloud Model Implementation\n",
    "\n",
    "The Water Cloud Model (WCM) by Prevot (1993) models the radar backscatter as a combination of:\n",
    "1. Direct vegetation contribution\n",
    "2. Attenuated soil contribution\n",
    "\n",
    "The model has 5 parameters (P1-P5) that need to be optimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wcm_1993_sigma_0(P1, P2, P3, P4, P5, L, S):\n",
    "    \"\"\"Prevot 1993 Water Cloud Model implementation.\n",
    "    \n",
    "    Args:\n",
    "        P1-P5: Model parameters to be optimized\n",
    "        L: Leaf Area Index\n",
    "        S: Soil Moisture\n",
    "        \n",
    "    Returns:\n",
    "        Estimated radar backscatter\n",
    "    \"\"\"\n",
    "    # Calculate two-way transmissivity\n",
    "    t2 = np.exp(-2 * P2 * L / np.cos(theta_rad))\n",
    "    \n",
    "    # Vegetation contribution\n",
    "    # Note: The (1-t2) factor is omitted as it was found to reduce R² score\n",
    "    sigma_veg = P1 * np.power(L, P5) * np.cos(theta_rad)\n",
    "    \n",
    "    # Soil contribution\n",
    "    sigma_soil = P3 + P4 * S\n",
    "    \n",
    "    # Total backscatter\n",
    "    return sigma_veg + (t2 * sigma_soil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization Functions\n",
    "\n",
    "We implement several optimization methods to find the best parameters for the WCM model:\n",
    "1. Least Squares (LS)\n",
    "2. Differential Evolution (DE) with local optimization\n",
    "\n",
    "Note: Basin-hopping was found to be unstable for this function and is commented out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_wcm_1993_sigma_0_ls(polarization, L, S):\n",
    "    \"\"\"Optimize WCM parameters using Least Squares method.\n",
    "    \n",
    "    Args:\n",
    "        polarization: VV or VH backscatter values\n",
    "        L: Leaf Area Index values\n",
    "        S: Soil Moisture values\n",
    "        \n",
    "    Returns:\n",
    "        Optimized parameters\n",
    "    \"\"\"\n",
    "    def residuals(params):\n",
    "        predicted = wcm_1993_sigma_0(*params, L, S)\n",
    "        residuals = predicted - polarization\n",
    "        # Handle numerical instabilities\n",
    "        if not np.all(np.isfinite(residuals)):\n",
    "            return np.ones_like(residuals) * np.inf \n",
    "        return residuals\n",
    "    \n",
    "    # Initial parameter guess\n",
    "    initial_guess = [0.1, 1.3, 1.2, 0.9, 0.8]\n",
    "    \n",
    "    # Optimize using least squares with robust loss function\n",
    "    result = least_squares(\n",
    "        residuals, \n",
    "        initial_guess, \n",
    "        method='trf',  # Trust Region Reflective algorithm\n",
    "        loss='soft_l1',  # Robust loss function\n",
    "        max_nfev=10000  # Maximum number of function evaluations\n",
    "    )\n",
    "    \n",
    "    return result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_wcm_1993_sigma_0_de_hybrid(polarization, L, S):\n",
    "    \"\"\"Optimize WCM parameters using Differential Evolution followed by local optimization.\n",
    "    \n",
    "    This hybrid approach first uses a global optimizer (Differential Evolution) to find\n",
    "    a good starting point, then refines it with a local optimizer (L-BFGS-B).\n",
    "    \n",
    "    Args:\n",
    "        polarization: VV or VH backscatter values\n",
    "        L: Leaf Area Index values\n",
    "        S: Soil Moisture values\n",
    "        \n",
    "    Returns:\n",
    "        Optimized parameters\n",
    "    \"\"\"\n",
    "    def objective(params):\n",
    "        predicted = wcm_1993_sigma_0(*params, L, S)\n",
    "        residuals = predicted - polarization\n",
    "        # Use sum of squared residuals as objective\n",
    "        return np.sum(residuals**2)  \n",
    "\n",
    "    # Parameter bounds\n",
    "    bounds = [(-10, 10), (-10, 10), (-10, 10), (-10, 10), (0.01, 10)]  \n",
    "    \n",
    "    # First stage: global optimization with Differential Evolution\n",
    "    result_de = differential_evolution(\n",
    "        objective,\n",
    "        bounds,\n",
    "        maxiter=1000,  # Maximum number of generations\n",
    "        popsize=20,    # Population size\n",
    "        tol=1e-6,      # Convergence tolerance\n",
    "        mutation=(0.5, 1.0),  # Mutation constant\n",
    "        recombination=0.7,    # Recombination constant\n",
    "        seed=42              # For reproducibility\n",
    "    )\n",
    "    \n",
    "    # Second stage: local optimization starting from DE result\n",
    "    result_local = minimize(\n",
    "        objective, \n",
    "        result_de.x, \n",
    "        method='L-BFGS-B',  # Limited-memory BFGS with bounds\n",
    "        bounds=bounds\n",
    "    )\n",
    "    \n",
    "    return result_local.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wcm_1993_validate_optimizer(optimizer_func, data, plot=True):\n",
    "    \"\"\"Validate WCM optimizer performance for both VV and VH polarizations.\n",
    "    \n",
    "    Args:\n",
    "        optimizer_func: Function to optimize WCM parameters\n",
    "        data: DataFrame containing the data\n",
    "        plot: Whether to plot the results\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (predicted_VV, predicted_VH)\n",
    "    \"\"\"\n",
    "    # Optimize for VV polarization\n",
    "    params_VV = optimizer_func(VV_dB, LAI, SM)\n",
    "    predicted_VV = wcm_1993_sigma_0(*params_VV, LAI, SM)\n",
    "    r2_VV = r2_score(VV_dB, predicted_VV)\n",
    "    rmse_VV = np.sqrt(mean_squared_error(VV_dB, predicted_VV))\n",
    "\n",
    "    # Optimize for VH polarization\n",
    "    params_VH = optimizer_func(VH_dB, LAI, SM)\n",
    "    predicted_VH = wcm_1993_sigma_0(*params_VH, LAI, SM)\n",
    "    r2_VH = r2_score(VH_dB, predicted_VH)\n",
    "    rmse_VH = np.sqrt(mean_squared_error(VH_dB, predicted_VH))\n",
    "\n",
    "    # Clear previous output and display results\n",
    "    clear_output()\n",
    "    print(f\"WCM Model Parameters (VV): {params_VV}\")\n",
    "    print(f\"WCM Model Parameters (VH): {params_VH}\")\n",
    "    print(f\"R² Score for VV: {r2_VV:.4f}\")\n",
    "    print(f\"RMSE for VV: {rmse_VV:.4f} dB\")\n",
    "    print(f\"R² Score for VH: {r2_VH:.4f}\")\n",
    "    print(f\"RMSE for VH: {rmse_VH:.4f} dB\")\n",
    "    \n",
    "    # Plot results if requested\n",
    "    if plot:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "        \n",
    "        # VV plot\n",
    "        axes[0].scatter(VV_dB, predicted_VV, alpha=0.7)\n",
    "        min_val = min(VV_dB.min(), predicted_VV.min())\n",
    "        max_val = max(VV_dB.max(), predicted_VV.max())\n",
    "        axes[0].plot([min_val, max_val], [min_val, max_val], 'r--')\n",
    "        axes[0].set_xlabel('Observed VV (dB)')\n",
    "        axes[0].set_ylabel('Predicted VV (dB)')\n",
    "        axes[0].set_title(f'VV Polarization (R² = {r2_VV:.4f}, RMSE = {rmse_VV:.4f} dB)')\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # VH plot\n",
    "        axes[1].scatter(VH_dB, predicted_VH, alpha=0.7)\n",
    "        min_val = min(VH_dB.min(), predicted_VH.min())\n",
    "        max_val = max(VH_dB.max(), predicted_VH.max())\n",
    "        axes[1].plot([min_val, max_val], [min_val, max_val], 'r--')\n",
    "        axes[1].set_xlabel('Observed VH (dB)')\n",
    "        axes[1].set_ylabel('Predicted VH (dB)')\n",
    "        axes[1].set_title(f'VH Polarization (R² = {r2_VH:.4f}, RMSE = {rmse_VH:.4f} dB)')\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return (predicted_VV, predicted_VH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate WCM with Different Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate WCM with Least Squares optimizer\n",
    "print(\"Evaluating WCM with Least Squares optimizer...\")\n",
    "pred_VV_ls, pred_VH_ls = wcm_1993_validate_optimizer(optimize_wcm_1993_sigma_0_ls, data_trimmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate WCM with Differential Evolution + Local optimizer\n",
    "print(\"Evaluating WCM with Differential Evolution + Local optimizer...\")\n",
    "pred_VV_de, pred_VH_de = wcm_1993_validate_optimizer(optimize_wcm_1993_sigma_0_de_hybrid, data_trimmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Model Stacking\n",
    "\n",
    "We use the WCM predictions as features for machine learning models to improve the overall prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for ML model stacking\n",
    "df = pd.read_csv(r\"../Data/Merged_Data.csv\")\n",
    "\n",
    "# Get predictions from the best WCM model (DE hybrid)\n",
    "pred_VV, pred_VH = pred_VV_de, pred_VH_de\n",
    "\n",
    "# Create feature matrix\n",
    "X = df[['LAI', 'SM']].copy()\n",
    "X['pred_VV'] = pred_VV\n",
    "X['pred_VH'] = pred_VH\n",
    "\n",
    "# Create target variables (residuals between observed and WCM predictions)\n",
    "y_vv = df['VV'] - X['pred_VV']\n",
    "y_vh = df['VH'] - X['pred_VH']\n",
    "\n",
    "# Split into train/test sets (80% train, 20% test)\n",
    "X_train, X_test, y_vv_train, y_vv_test = train_test_split(X, y_vv, test_size=0.2, random_state=42)\n",
    "_, _, y_vh_train, y_vh_test = train_test_split(X, y_vh, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  }]
}